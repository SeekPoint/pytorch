PyTorch 分布式(1) --- 数据加载之DistributedSampler
https://www.cnblogs.com/rossiXYZ/p/15142807.html


0x00 摘要
为了更好的介绍参数服务器Paracel的数据加载，我们临时插入两篇PyTorch的数据加载（因为字数太长，所以拆成两篇），主要是从分布式的角度进行切入。本文只算是开胃甜点，后续会有专门系列分析PyTorch分布式。

参数服务器系列其他文章如下：

[源码解析] 机器学习参数服务器ps-lite 之(1) ----- PostOffice

[源码解析] 机器学习参数服务器ps-lite(2) ----- 通信模块Van

[源码解析] 机器学习参数服务器ps-lite 之(3) ----- 代理人Customer

[源码解析]机器学习参数服务器ps-lite(4) ----- 应用节点实现

[源码解析] 机器学习参数服务器 Paracel (1)-----总体架构

[源码解析] 机器学习参数服务器 Paracel (2)--------SSP控制协议实现

0x01 数据加载
1.1 加速途径
当分布式训练时候，为了加速训练，有三个层面的工作需要处理。
    数据加载层面
    多机通讯层面
    代码层面

在数据层面，可以使用多进程并行加载来加速数据预处理过程，也有利用GPU特点来加速，比如Nvidia DALI 通过将数据预处理放到 GPU 处理来解决 CPU 瓶颈问题。

在多机通讯层面，有各种集合通信库可以利用，比如NCCL，OpenMPI, Gloo 等。

在代码层面，可以使用框架提供的分布式API，或者利用 Horovod 来改造单机版代码，使其支持分布式任务。

接下来我们就看看数据层面如何加速。

1.2 并行处理
AI框架的数据处理主要如下并行处理：

    数据加载/处理使用CPU。
    训练使用GPU。

在理想状态下，应该是每轮迭代训练之前，CPU就完成加载，准备好训练数据，这样训练就可以持续无缝迭代。

然而，GPU算力每年会提升一倍，CPU的提升速度远远落后于GPU，所以CPU会是拖后腿的那个角色。
这里不仅仅是CPU算力不足的问题，也包括村存储中读取数据速度不足的问题。

因此，机器学习对于数据加载和前期预处理的要求越来越高，必须在GPU计算时间内，完成下一迭代数据的准备工作，不能让GPU因为等待训练数据而空闲。

1.3 流水线
对于机器学习训练，加载数据可以分为三个步骤：

    将数据从磁盘或者分布式存储加载到主机（CPU）。
    将数据从主机可分页内存传输到主机固定内存。
    将数据从主机固定内存转移到主机GPU。

因此，流行的深度学习框架会依据加载步骤的特点和异构硬件的特点来进行流水线处理，从而提高数据处理过程的吞吐量。

流水线一般包括多个算子，每个算子内部由数据队列组成一个缓冲区，上游算子完成处理之后会传给给下游算子进行处理。
这样每个算子任务会彼此独立，算子内部可以使用细粒度的多线程/多进程来并行加速，
每个算子可以独立控制处理速度和内存以适配不同网络对于处理速度的需求。

如果算子内部数据队列不为空，模型就会一直源源不断获得数据，就不会因为等待训练数据而产生瓶颈。

下面是串行处理逻辑：

+------+            +-----------+           +---------------------------+
|      |            |           |           |                           |
| Data +----------> | Load Data +---------> | Transfer to Pinned Memory |
|      |            |           |           |                           |
+------+            +-----------+           +---------------------------+
下面是并行流水线逻辑：

                    +------------+
+--------+          |            |
|        |          | Process 1  |
| Data 1 +--------> |            +------+
|        |          | Load Data  |      |
+--------+          |            |      |
                    +------------+      |
                                        |
                                        |
                                        |
                    +------------+      |        +-----------------------------------+
+--------+          |            |      |        |                                   |
|        |          | Process 2  |      +------> | Pin-memory process                |
| Data 2 +--------> |            |               |                                   |
|        |          | Load Data  +-------------> |                                   |
+--------+          |            |               |        Transfer to Pinned Memory  |
                    +------------+       +-----> |                                   |
                                         |       |                                   |
                                         |       +-----------------------------------+
                                         |
+--------+          +------------+       |
|        |          |            |       |
| Data 3 +--------> | Process 3  +-------+
|        |          |            |
+--------+          | Load Data  |
                    |            |
                    +------------+

1.4 GPU
本文到现在是解决CPU侧的数据传输问题，即：从磁盘加载数据，从可分页到固定内存。

但是，从固定内存到GPU的数据传输（tensor.cuda()）也可以使用CUDA流进行流水线处理。

另外，深度学习应用程序需要复杂的多阶段数据处理管道，包括加载、解码、裁剪、调整大小和许多其他增强功能。
这些目前在 CPU 上执行的数据处理管道已经成为瓶颈，限制了训练和推理的性能和可扩展性。

Nvidia DALI 通过将数据预处理放到 GPU 处理来解决 CPU 瓶颈问题，用户可以依据自己模型的特点，
构建基于 GPU 的 pipeline，或者基于CPU的pipeline。
        02-01.svg

接下来我们就介绍PyTorch的数据加载，而且主要是从分布式的角度进行切入。

0x02 PyTorch分布式加载
2.1 DDP
pytorch为数据分布式训练提供了多种选择。随着应用从简单到复杂，从原型到产品，常见的开发轨迹可以是：

    如果数据和模型能放入单个GPU，使用单设备训练，此时不用担心训练速度；
    如果服务器上有多个GPU，并且你在代码修改量最小的情况下加速训练，使用单个机器多GPU DataParallel；
    如果你想进一步加速训练并且愿意写一点代码来启动，使用单个机器多个GPU DistributedDataParallel；
    如果应用程序跨机器边界扩展，使用多机器DistributedDataParallel和启动脚本；
    如果预期有错误（比如OOM）或者资源在训练过程中可以动态连接和分离，使用torchelastic来启动分布式训练。

与本文最相关的部分就是DDP，Distributed Data-Parallel Training（DDP）是一个广泛采用的单程序多数据训练方法。
使用DDP，模型会被复制到每个进程，然后每个模型副本会被输入数据样本的不同子集。
DDP负责梯度通信以保持模型副本的同步，并将其与梯度计算重叠以加快训练速度。


2.2 分布式加载
我们首先要看看分布式加载的总体结构。
给出示例代码，可以看到主要使用了 DataSet, DistributedSampler，DataLoader 这三个实体。

    sampler = DistributedSampler(dataset) if is_distributed else None
    loader = DataLoader(dataset, shuffle=(sampler is None), sampler=sampler)
    for epoch in range(start_epoch, n_epochs):
        if is_distributed:
            sampler.set_epoch(epoch)
            train(loader)
这三个概念的逻辑关系如下：

    Dataset : 从名字可以知道，是数据集的意思。
    负责对原始训练数据的封装，将其封装成 Python 可识别的数据结构，Dataset的派生类必须提供接口一边获取单个数据。

    Sampler : 从名字可知，是采样器，负责采样方式或者说是采样策略，实现某种提取/采样策略从Dataset之中拿到数据索引，供DataLoade使用。
    可以认为，Sampler 是指挥者，负责决定战斗在哪里开展。

    DataLoader : 负责依据索引来从数据集中加载数据。
    支持 Map-style 和 Iterable-style 两种Dataset，支持单进程/多进程加载。
    Loader 就是具体作战的斗士，负责按照 Sampler的命令进行战斗。

具体如下图，简要说就是：

    DataSet 把数据集数目发给DistributedSampler。
    Sampler 按照某种规则发送数据indices给Loader。
    Loader 依据indices加载数据。
    Loader 把数据发给模型，进行训练。
+------------------------+                     +-----------+
|DistributedSampler      |                     |DataLoader |
|                        |     2 indices       |           |
|    Some strategy       +-------------------> |           |
|                        |                     |           |
|-------------+----------|                     |           |
              ^                                |           |  4 data  +-------+
              |                                |       -------------->+ train |
            1 | length                         |           |          +-------+
              |                                |           |
+-------------+----------+                     |           |
|DataSet                 |                     |           |
|        +---------+     |      3 Load         |           |
|        |  Data   +-------------------------> |           |
|        +---------+     |                     |           |
|                        |                     |           |
+------------------------+                     +-----------+
因为数据集不是分布式训练重点，所以本文接下来主要分析 Sampler。
Sampler 的重点就是：如何让每个worker在数据集中只加载自己所属的部分，并且worker之间实现对数据集的正交分配。

0x03 DistributedSampler
对于数据并行和分布式训练，DistributedSampler 负责其数据采样的任务。

DistributedSampler 是 Sampler 的派生类。当 DistributedDataParallel 使用DistributedSampler 时，
每个并行的进程都会得到一个DistributedSampler 实例，这个DistributedSampler 实例会给DataLoader发送指示，从而 DataLoader 加载具体数据。

DistributedSampler 加载策略负责只提供加载数据集中的一个子集，这些DistributedSampler 提供的子集之间不重叠，不交叉。


...


0xFF 参考
卷积神经网络的并行化模型--One weird trick for parallelizing convolutional neural networks

AI框架中数据处理的挑战与解决思路

PyTorch 源码解读之 torch.utils.data：解析数据处理全流程

谈谈你对大规模机器学习这个领域的理解和认识?

Nvidia-DALI 从放弃到入门

pytorch(分布式)数据并行个人实践总结——DataParallel/DistributedDataParallel